let WIDTH = 800;
let HEIGHT = 600;

// Helper function to convert RGB values to a 32-bit color
fun rgb32(r, g, b) {
    return 0xFF_00_00_00 | (r << 16) | (g << 8) | b;
}

let BLACK = rgb32(0, 0, 0);
let BLUE = rgb32(50, 100, 255);
let WHITE = rgb32(255, 255, 255);

// --- Audio State ---
let SAMPLE_RATE = 44100;
let NUM_CHANNELS = 1;
let var recording = false;

class WavePlot {
    init(self, width, height, color) {
        self.width = width;
        self.height = height;
        self.color = color;
        self.audio_data = ByteArray.with_size(0);
        self.num_samples = 0; // Initialize num_samples
        self.magnitude_buckets = Array.with_size(100, 0); // 100 buckets for magnitudes [0, 1]
        self.max_sample_range = 0.0; // Initialize max_sample_range
    }

    append_samples(self, new_samples) {
        let new_size = self.audio_data.len + new_samples.len;
        let new_buffer = ByteArray.with_size(new_size);
        new_buffer.memcpy(0, self.audio_data, 0, self.audio_data.len);
        new_buffer.memcpy(self.audio_data.len, new_samples, 0, new_samples.len);
        self.audio_data = new_buffer;

        // Update num_samples
        let num_new_samples = new_samples.len _/ 4;
        self.num_samples = self.num_samples + num_new_samples;

        // Update magnitude_buckets
        for (let var i = 0; i < num_new_samples; i = i + 1) {
            let sample = new_samples.read_f32(i);
            let abs_sample = sample.abs();

            // Increment magnitude bucket
            let bucket_idx = (abs_sample * 100).floor().min(99); // Clamp to 99 for the last bucket
            self.magnitude_buckets[bucket_idx] = self.magnitude_buckets[bucket_idx] + 1;
        }

        // Calculate 99th percentile magnitude for normalization (max_sample_range)
        let target_samples = self.num_samples * 0.99;
        let var cumulative_samples = 0;
        let var calculated_max_sample_range = 0.0;
        for (let var i = 0; i < 100; ++i) {
            cumulative_samples = cumulative_samples + self.magnitude_buckets[i];
            if (cumulative_samples >= target_samples) {
                // Upper bound of the bucket
                calculated_max_sample_range = (i + 1).to_f() / 100.0;

                break;
            }
        }

        // Fallback if no samples or all samples are very small
        if (calculated_max_sample_range == 0.0) {
            self.max_sample_range = 0.01; // A small default to avoid division by zero
        } else {
            self.max_sample_range = calculated_max_sample_range * 1.20;
        }
    }

    clear_samples(self) {
        self.audio_data = ByteArray.with_size(0);
        self.num_samples = 0; // Reset num_samples
        self.magnitude_buckets = Array.with_size(100, 0); // Reset magnitude buckets
        self.max_sample_range = 0.0; // Reset max_sample_range
    }

    redraw(self, frame_buffer) {
        // Clear the buffer
        frame_buffer.zero_fill();

        if (self.num_samples == 0 || self.max_sample_range == 0.0) {
            return;
        }

        // For each column of the frame buffer
        for (let var i = 0; i < self.width; ++i)
        {
            let samples_per_col = (self.num_samples / self.width).max(1.0).min(200.0).floor();
            let start_idx = ((i / (self.width - 1)) * (self.num_samples - 1)).floor();
            let end_idx = (start_idx + samples_per_col).min(self.num_samples);

            // Determine the max sample value for this column
            let var max_sample = 0.0;
            for (let var k = start_idx; k < end_idx; ++k)
                max_sample = max_sample.max(self.audio_data.read_f32(k));

            // Compute the Y coordinate in the frame buffer for this sample
            let norm_v = (max_sample / self.max_sample_range).min(1.0).max(-1.0);
            let pos_v = ((1.0 + norm_v) / 2.0).min(1.0);
            let j = (pos_v * (self.height - 1)).floor();

            let mid_y = self.height _/ 2;
            let end_y = (j - mid_y).abs();
            for (let var k = mid_y - end_y; k < mid_y + end_y; ++k) {
                frame_buffer.write_u32(k * self.width + i, self.color);
            }
        }
    }
}

// --- Main Program ---
let frame_buffer = ByteArray.with_size(WIDTH * HEIGHT * 4);
let window = $window_create(WIDTH, HEIGHT, "Audio Recorder", 0);
let audio_in = $audio_open_input(SAMPLE_RATE, NUM_CHANNELS);
let wave_plot = WavePlot(WIDTH, HEIGHT, BLUE);

$println("Press SPACE to record audio, press again to stop recording");

loop {
    // --- Event Handling ---
    let msg = $actor_poll();

    if (msg instanceof UIEvent) {
        if (msg.kind == 'CLOSE_WINDOW' || (msg.kind == 'KEY_DOWN' && msg.key == 'ESCAPE')) {
            break;
        }

        if (msg.kind == 'KEY_DOWN' && msg.key == 'SPACE') {
            recording = !recording;
            if (recording) {
                $println("Recording started...");
                wave_plot.clear_samples();
            } else {
                $println("Recording stopped.");
            }
        }
    }

    // Block and read a chunk of audio data
    let chunk = ByteArray.with_size(1024 * 4);
    $audio_read_samples(audio_in, 1024, chunk, 0);

    if (recording) {
        wave_plot.append_samples(chunk);
    }

    // --- Drawing ---
    wave_plot.redraw(frame_buffer);
    $window_draw_frame(window, frame_buffer);
}
